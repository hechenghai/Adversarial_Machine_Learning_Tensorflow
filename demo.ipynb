{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Machine Learning With Tensorflow\n",
    "Welcome to the demo. Adversarial machine learning has two sides to the coin: \n",
    "*Adversarial Attacks* and *Adversarial Defenses*. The attacks try to generate perturbed images which fool a classification model\n",
    "without falling out of the class conditional data distribution. Defense techniques aim at making models robust to \n",
    "adversarial attacks. I assume you are familiar with these concepts. If not check out e.g \n",
    "[https://adversarial-ml-tutorial.org/introduction/](https://adversarial-ml-tutorial.org/introduction/) for a gentle introduction\n",
    "with complementary code in PyTorch. This demo will study the adversarial robustness of neural network models on MNIST with Tensorflow.\n",
    "For that we need adversarial attacks and models that try to defend against adversarial attacks.\n",
    "\n",
    "### Adverarial Attacks\n",
    "I implemented the adversarial attacks from scratch in the `adversarial_ml` package that can be found in the\n",
    "[repository of this notebook](https://github.com/skmda37/Adversarial_Machine_Learning_Tensorflow). Below is a list\n",
    "of all the attacks that are used in this notebook and a link to their original paper:\n",
    "\n",
    "- Fast Gradient Sign Method ([Explaining And Harnessing Adversarial Examples - Goodfellow et al](https://arxiv.org/pdf/1412.6572.pdf))\n",
    "- Step Least Likely ([Adversarial Machine Learning at Scale - Kurakin et al.](https://arxiv.org/pdf/1611.01236.pdf))\n",
    "- Basic Iterative Method ([Adversarial Machine Learning at Scale - Kurakin et al.](https://arxiv.org/pdf/1611.01236.pdf))\n",
    "- Iterative Least Likely ([Adversarial Machine Learning at Scale - Kurakin et al.](https://arxiv.org/pdf/1611.01236.pdf))\n",
    "- Random Plus FGSM ([Fast Is Better Than Free: Revisiting Adversarial Training - Rice and Wong et al.](https://arxiv.org/pdf/2001.03994.pdf))\n",
    "- PGD With Random Restarts ([https://arxiv.org/pdf/1706.06083.pdf](https://arxiv.org/pdf/1706.06083.pdf))\n",
    "\n",
    "### Adversarial Defenses\n",
    "We focus on the most common and arguably most effective adversarial defense: **Adversarial Training**. The idea is quite simple. \n",
    "The adversarial training algorithm simply injects adversarial examples generated by some adversarial attack into the\n",
    "training batch at each iteration of the training algorithm. This way the model is trained on both clean images as well as adversarial\n",
    "examples. There many hyper-parameters of adversarial training such as:\n",
    "\n",
    "- the number of adversarial examples injected into the training batch\n",
    "- the type of adversarial exmaples in the training batch, i.e. the attack used for generating adversarial examples\n",
    "- the relative weight of the adversarial examples in the loss function\n",
    "\n",
    "This notebook will not go into the details of the effects of these parameters. If you are interested, you can read\n",
    "into [\"Adversarial Machine Learning at Scale\" - Kurakin et al.](https://arxiv.org/pdf/1611.01236.pdf) which studies adversarial training on ImageNet extensively and among other things talks about the effects\n",
    "of different hyper-parameters in adversarial training on ImageNet. As a matter of fact we will\n",
    "\n",
    "- train on training batches with half of the images being adversarial examples\n",
    "- experiment with every adversarial attack listed in the section above\n",
    "- weigh adversarial examples and clean images equally in the loss function for training\n",
    "\n",
    "### What will you see in this demo\n",
    "\n",
    "You will how different models trained on MNIST have different adversarial vulnerbailities. We will first compare fully connected\n",
    "neural networks and convoltuional neural networks without adversarial training. Then we will see the drastic improvement w.r.t.\n",
    "adversarial vulnerability by using adversarial training with virtually any of the adversarial attacks. Nevertheless as we will see\n",
    "some types of adversarial examples for adversarial training results in much better defenses than other. Similarly we will also\n",
    "see that some adversarial attacks are much harder to defend against than others. The demo will show you which attacks are the\n",
    "hardest to defend against and which type of adversarial exampels for adversarial training results in the best defense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from adversarial_ml import adversarial_attacks as attacks\n",
    "from adversarial_ml import custom_model as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset\n",
    "We load the training data `(x_train,y_train)` and test data `(x_test,y_test)`. Then we perform some preprocessing. The data\n",
    "is stored as `tf.Tensor` of shape `(number_images, height, width, color_channel)` and type float32. The entries of the\n",
    "tensors are scaled between 0 and 1 hence we divide each entry by the maximal pixel value 255.\n",
    "\n",
    "The shapes of the data are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess\n",
    "x_train = tf.constant(x_train.reshape(60000,28, 28,1).astype(\"float32\") / 255)\n",
    "x_test = tf.constant(x_test.reshape(10000, 28, 28, 1).astype(\"float32\") / 255)\n",
    "\n",
    "y_train = tf.constant(y_train.astype(\"float32\"))\n",
    "y_test = tf.constant(y_test.astype(\"float32\"))\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model Architecture\n",
    "We will look at two types of model architecture: **Fully connected neural networks (fc)**\n",
    "and **convolutional neural networks (cnn)**.\n",
    "\n",
    "Below we define the parameters for each of the layers in the fully connected neural networks as well as for the \n",
    "convolutional neural networks. You can play around with this yourself and change the architecture, e.g. add more layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the architecture of fully connected neural networks\n",
    "class FcParams(object):\n",
    "    def __init__(self):\n",
    "        self.input_shape = [28,28,1]\n",
    "        self.num_classes = 10\n",
    "        self.num_fc_units = [64,32,32]\n",
    "\n",
    "# Parameters for the architecture of convolutional neural networks\n",
    "class CnnParams(object):\n",
    "    def __init__(self):\n",
    "        # Model hyperparameters\n",
    "        self.input_shape = [28, 28, 1]\n",
    "        self.num_classes = 10\n",
    "        self.num_conv_filters = [32, 64, 64]\n",
    "        self.kernel_size = (3, 3)\n",
    "        self.pool_size = (2, 2)\n",
    "        self.num_fc_units = [64]\n",
    "        \n",
    "fc_params = FcParams()\n",
    "cnn_params = CnnParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define two functions `get_cnn_model` and `get_fc_model` which return a convolutional neural network and \n",
    "a fully connected neural network respectively after specifiying two inputs: (1)`adv_training_with` which specifies if the model\n",
    "will be trained adversarially and if so with what hyper-parameters (2) `gaussian_noise` which is the amount\n",
    "of noise to put in the first layer of the model. We will use the default `gaussian_noise=0.2`. Adding noise to the training data\n",
    "(not test data) when performing a forward pass is a nice little regularization. As you will see most adversarial attacks start being\n",
    "effective when using a maximal perturbation size $\\epsilon = 0.2$ out of $[0,1]$ which can be visually perceived as grainy noise.\n",
    "Hence we will train on noisy training data. You will see that you cannot simply defend against attacks by training on noisy data\n",
    "as comfortable as that would be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(adv_training_with=None, gaussian_noise=0.2):\n",
    "    # Define Model layers\n",
    "    inputs = tf.keras.Input(shape=cnn_params.input_shape,\n",
    "                            dtype=tf.float32, name=\"image\")\n",
    "\n",
    "    x = inputs\n",
    "    x = tf.keras.layers.GaussianNoise(stddev=gaussian_noise)(x)\n",
    "    \n",
    "    # Convolutional layer followed by \n",
    "    for i, num_filters in enumerate(cnn_params.num_conv_filters):\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            num_filters, cnn_params.kernel_size, activation='relu')(x)\n",
    "        if i < len(cnn_params.num_conv_filters) - 1:\n",
    "            # max pooling between convolutional layers\n",
    "            x = tf.keras.layers.MaxPooling2D(cnn_params.pool_size)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    for num_units in cnn_params.num_fc_units:\n",
    "        x = tf.keras.layers.Dense(num_units, activation='relu')(x)\n",
    "\n",
    "    pred = tf.keras.layers.Dense(cnn_params.num_classes, activation='softmax')(x)\n",
    "    \n",
    "\n",
    "    return models.CustomModel(inputs=inputs, outputs=pred, \n",
    "                              adv_training_with=adv_training_with)\n",
    "\n",
    "def get_fc_model(adv_training_with=None, gaussian_noise=0.2):\n",
    "    # Input shape \n",
    "    inputs = tf.keras.Input(shape=fc_params.input_shape, \n",
    "                            dtype=tf.float32, name=\"image\")\n",
    "\n",
    "    x = inputs\n",
    "    x = tf.keras.layers.GaussianNoise(stddev=gaussian_noise)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    for num_units in fc_params.num_fc_units:\n",
    "        x = tf.keras.layers.Dense(num_units, activation='relu')(x)\n",
    "\n",
    "    pred = tf.keras.layers.Dense(fc_params.num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return models.CustomModel(inputs=inputs, outputs=pred, \n",
    "                                    adv_training_with=adv_training_with)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Parameters\n",
    "Here we will set some global constant parameters for training. These parameters are used for training of every model in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "METRICS = [tf.keras.metrics.SparseCategoricalAccuracy]\n",
    "OPTIMIZER = tf.keras.optimizers.RMSprop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Model Without Adversarial Training\n",
    "We start with a fully connected neural network that we will assign to `fc_model`. Below we print out a summary of the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "fc_model = get_fc_model()\n",
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we train the fully connected model **without adversarial training**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "fc_model.compile(optimizer=OPTIMIZER,\n",
    "              loss=LOSS, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train Model\n",
    "fc_model.fit(x_train, y_train,\n",
    "             batch_size=32,\n",
    "             epochs=4, validation_split=0.2)\n",
    "\n",
    "# Evaluate Model\n",
    "print(\"\\nEvaluation on clean test data:\\n\")\n",
    "evaluation = fc_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Robustness For Fully Connected Neural Network\n",
    "Let's visualize the results of an adversarial attack (Random Plus FGSM)) on the fullly connected model by displaying the predictions of the model for 20 clean test images and \n",
    "their corresponding adversarial examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack to be tested\n",
    "Attack = attacks.RandomPlusFgsm\n",
    "# Attack parameters\n",
    "attack_kwargs = {\"eps\": 0.2, \"alpha\": 1.25*0.2}\n",
    "\n",
    "\n",
    "attacks.attack_visual_demo(fc_model, Attack, attack_kwargs,\n",
    "                           x_test[:20], y_test[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every model instance of `models.CustomModel` has a method `test_adv_robustness` which can be called on test data and prints accuracy results\n",
    "on adversarial examples of different types. \n",
    "\n",
    "Let's test the adversarial robustness for the fully connected model by calling this method on\n",
    "the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Adversarial Robustness\n",
    "fc_model.test_adv_robustness(x_test, y_test, eps=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every attack ($\\epsilon=0.2$ is the default for our adversarial robustness test) manages to keep accuracy below 16%. \n",
    "The most effective attack is the *Basic Iterative Method* and the least effective attack is *One Step Least Likely*.\n",
    "\n",
    "This is not surprising to me since the iterative method performs several (in the test 40) iterations of gradient ascent/descent and has thus more power\n",
    "to minimize/maximize the adversarial objective.\n",
    "\n",
    "In the case of *One Step Least Likely* keep in mind that the method performs only \n",
    "one step (like FGSM, Random Plus FGSM) but optimizes for a classification equal to the least likely predicted label for the clean input \n",
    "(unlike FGSM and Random Plus FGSM). \n",
    "\n",
    "Steering the model to the least likely predicted label (think label airplane for an image of a panda) is surely a more difficult\n",
    "objective than say reducing directly the confidence of the model in the true label (FGSM, Random Plus FGSM, Basic Iterative do this).\n",
    "\n",
    "Our take away is: Fully connected models without adversarial training are extremely vulnerable to adversarial attacks.\n",
    "Let's see how vanilla convolutional neural networks compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Without Adversarial Training\n",
    "Now we get a convolutional neural networks and assign it to `cnn_model`. Below we also print a summary of the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = get_cnn_model()\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the network for as many epochs as the fully connected model (we don't change the epochs throughout the experimetns of the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "cnn_model.compile(optimizer=OPTIMIZER,\n",
    "              loss=LOSS, metrics=[\"accuracy\"])\n",
    "# Train Model \n",
    "cnn_model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=4, validation_split=0.2)\n",
    "\n",
    "# Evaluate Model\n",
    "print(\"\\n\")\n",
    "evaluation = cnn_model.evaluate(x_test,y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we visualize again for fun's sake how our model performs on the Random Plus FGSM attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack to be tested\n",
    "Attack = attacks.RandomPlusFgsm\n",
    "# Attack parameters\n",
    "attack_kwargs = {\"eps\": 0.2, \"alpha\": 1.25*0.2}\n",
    "\n",
    "\n",
    "attacks.attack_visual_demo(cnn_model, Attack, attack_kwargs,\n",
    "                           x_test[:20], y_test[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes these are just 20 pictures but wow! Compared to the picture for the `fc_model` we are much more robust to the adversarial attack. \n",
    "\n",
    "Is that just coincidence? Is this not representative? Let's find out by calling `cnn_model.test_adv_robustness` for a rigorous test on\n",
    "the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Adversarial Robustness\n",
    "print(\"\\n\")\n",
    "cnn_model.test_adv_robustness(x_test, y_test, eps=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paints a clear picture. We drastically imporved our adversarial robustness by using a convolutional neural network\n",
    "(`cnn_model`) instead of a fully connected neural network (`fc_model`). There is a very clear argument. Fully connected neural networks\n",
    "are very prone to overfit. They are powerful models and can learn many functions and thus also many features. The problem \n",
    "that comes with that is that the model has no incnetive to learn for instance geometric shapes like we would for the classification task.\n",
    "\n",
    "The convolutional neural network comes with an architecture that extracts features in a way that is suitable for computer vision.\n",
    "Earch filter in a convilutional layer, as you surely know, slides lika a window over the previous layers and extracts features \n",
    "in a spatially invariant manner. This bias in the set of functions that can be learned helps the model learn features\n",
    "that generalize well. This makes it harder for adversarial attacks to be effective against the CNN because they look for\n",
    "features that are *not robust but predicitive* and can be injected with a small perturbation.\n",
    "\n",
    "We are not too happy though. The accuracy on adversarial examples drasticallly improved but not to an acceptable level.\n",
    "\n",
    "The basic iterative method is still classified correctly at an embarassingly low rate. Let's see if adversarial training is \n",
    "a game changer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training (With CNN Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since fully conncected models are extremely vulnerable to adversarial attacks and inferior architectures for computer vision\n",
    "we will continue looking at CNN (convolutional neural networks) models only. \n",
    "\n",
    "In this section we will look at adversarial training of CNN models only and take a look at what type of adversarial examples are \n",
    "the most effective defense.\n",
    "\n",
    "Hence each next subsection specifies an adversarial attack that is used to generate the adversarial examples for the adversarial \n",
    "training algorithm. We start with adversarial examples generated with FGSM for adversarial trainining. \n",
    "\n",
    "We use a maximal perturbation size of $\\epsilon=0.3$ for the adversarial examples in the adversarial training algorithm.\n",
    "\n",
    "The number of adversarial examples in each training batch is 16 out of 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training With FGSM\n",
    "Let's take a look at adversarial training with the simple FGSM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Adversarial Training Parameters\n",
    "eps = 0.3\n",
    "attack_kwargs = {\"eps\": eps}\n",
    "adv_training_with = {\"attack\": attacks.Fgsm,\n",
    "                     \"attack kwargs\": attack_kwargs,\n",
    "                     \"num adv\": 16}\n",
    "\n",
    "cnn_model_fgsm = get_cnn_model(adv_training_with=adv_training_with)\n",
    "\n",
    "# Compile model\n",
    "cnn_model_fgsm.compile(optimizer=OPTIMIZER,\n",
    "                       loss=LOSS, metrics=[\"accuracy\"])\n",
    "cnn_model_fgsm.fit(x_train, y_train,\n",
    "                   batch_size=32,epochs=4,\n",
    "                   validation_split=0.2)\n",
    "# Evaluate model\n",
    "print(\"\\n\")\n",
    "evaluation = cnn_model_fgsm.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "# Test adversarial robustness\n",
    "print(\"\\n\")\n",
    "cnn_model_fgsm.test_adv_robustness(x_test, y_test, eps=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The adversarial robustness test:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training With Random+FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get adversarial training parameters\n",
    "eps = 0.3\n",
    "attack_kwargs = {\"eps\": eps, \"alpha\":1.25*eps}\n",
    "adv_training_with = {\"attack\": attacks.RandomPlusFgsm,\n",
    "                     \"attack kwargs\": attack_kwargs,\n",
    "                     \"num adv\": 16}\n",
    "# Build model\n",
    "cnn_model_random_plus_fgsm = get_cnn_model(adv_training_with=adv_training_with)\n",
    "\n",
    "# Compile model\n",
    "cnn_model_random_plus_fgsm.compile(optimizer=OPTIMIZER,\n",
    "                       loss=LOSS, metrics=[\"accuracy\"])\n",
    "\n",
    "#Train model\n",
    "cnn_model_random_plus_fgsm.fit(x_train, y_train,\n",
    "                   batch_size=32,epochs=4,\n",
    "                   validation_split=0.2)\n",
    "# Evaluate model\n",
    "print(\"\\n\")\n",
    "evaluation = cnn_model_fgsm.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "# Test adversarial robustness\n",
    "print(\"\\n\")\n",
    "cnn_model_random_plus_fgsm.test_adv_robustness(x_test, y_test, eps=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The adversarial robustness test:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training With Basic Iterative Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set adversarial training parameters\n",
    "eps = 0.3\n",
    "num_iter = 40\n",
    "attack_kwargs = {\"eps\": eps, \"alpha\": eps/num_iter,\n",
    "                 \"num_iter\": num_iter}\n",
    "adv_training_with = {\"attack\": attacks.BasicIter,\n",
    "                     \"attack kwargs\": attack_kwargs,\n",
    "                     \"num adv\": 16}\n",
    "\n",
    "# Build model\n",
    "cnn_model_basic_iter = get_cnn_model(adv_training_with=adv_training_with)\n",
    "\n",
    "# Compile model\n",
    "cnn_model_basic_iter.compile(optimizer=OPTIMIZER,\n",
    "                       loss=LOSS, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "cnn_model_basic_iter.fit(x_train, y_train,\n",
    "                   batch_size=32,epochs=4,\n",
    "                   validation_split=0.2)\n",
    "# Evaluate model\n",
    "print(\"\\n\")\n",
    "evaluation = cnn_model_basic_iter.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "# Test adversarial robustness\n",
    "print(\"\\n\")\n",
    "cnn_model_basic_iter.test_adv_robustness(x_test, y_test, eps=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The adversarial robustness test:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training With PGD With Random Restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set adversarial training parameters\n",
    "eps = 0.3\n",
    "num_iter = 40\n",
    "attack_kwargs = {\"eps\": eps, \"alpha\": eps/num_iter,\n",
    "                 \"num_iter\": num_iter, \"restarts\": 10}\n",
    "adv_training_with = {\"attack\": attacks.PgdRandomRestart,\n",
    "                     \"attack kwargs\": attack_kwargs,\n",
    "                     \"num adv\": 16}\n",
    "\n",
    "# Build model\n",
    "cnn_model_pgd = get_cnn_model(adv_training_with=adv_training_with)\n",
    "\n",
    "# Compile model\n",
    "cnn_model_pgd.compile(optimizer=OPTIMIZER,\n",
    "                       loss=LOSS, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "cnn_model_pgd.fit(x_train, y_train,\n",
    "                   batch_size=32,epochs=4,\n",
    "                   validation_split=0.2)\n",
    "# Evaluate model\n",
    "print(\"\\n\")\n",
    "evaluation = cnn_model_pgd.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "# Test adversarial robustness\n",
    "print(\"\\n\")\n",
    "cnn_model_pgd.test_adv_robustness(x_test, y_test, eps=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The adversarial robustness test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
