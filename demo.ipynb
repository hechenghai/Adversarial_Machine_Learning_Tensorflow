{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from adversarial_ml import adversarial_attacks as attacks\n",
    "from adversarial_ml import custom_model as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28, 1)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess\n",
    "x_train = tf.constant(x_train.reshape(60000,28, 28,1).astype(\"float32\") / 255)\n",
    "x_test = tf.constant(x_test.reshape(10000, 28, 28, 1).astype(\"float32\") / 255)\n",
    "\n",
    "y_train = tf.constant(y_train.astype(\"float32\"))\n",
    "y_test = tf.constant(y_test.astype(\"float32\"))\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hparams(object):\n",
    "    def __init__(self):\n",
    "        # Model hyperparameters\n",
    "        self.input_shape = [28, 28, 1]\n",
    "        self.num_classes = 10\n",
    "        self.num_conv_filters = [32, 64, 64]\n",
    "        self.kernel_size = (3, 3)\n",
    "        self.pool_size = (2, 2)\n",
    "        self.num_fc_units = [64]\n",
    "        self.total_batch_size = 32\n",
    "        self.adv_batch_size = 16\n",
    "        \n",
    "\n",
    "hparams = Hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(adv_training_with=None, gaussian_noise=0.2):\n",
    "    # Define Model layers\n",
    "    inputs = tf.keras.Input(\n",
    "        shape=[28,28,1], dtype=tf.float32, name=\"image\")\n",
    "\n",
    "    x = inputs\n",
    "    x = tf.keras.layers.GaussianNoise(stddev=gaussian_noise)(x)\n",
    "    # Convolutional layer followed by \n",
    "    for i, num_filters in enumerate(hparams.num_conv_filters):\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            num_filters, hparams.kernel_size, activation='relu')(x)\n",
    "        if i < len(hparams.num_conv_filters) - 1:\n",
    "            # max pooling between convolutional layers\n",
    "            x = tf.keras.layers.MaxPooling2D(hparams.pool_size)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    for num_units in hparams.num_fc_units:\n",
    "        x = tf.keras.layers.Dense(num_units, activation='relu')(x)\n",
    "\n",
    "    pred = tf.keras.layers.Dense(hparams.num_classes, activation='softmax')(x)\n",
    "    \n",
    "\n",
    "    return models.CustomModel(inputs=inputs, outputs=pred, \n",
    "                                    adv_training_with=adv_training_with)\n",
    "\n",
    "def get_fcc_model(adv_training_with=None, gaussian_noise=0.2):\n",
    "    # Input shape \n",
    "    inputs = tf.keras.Input(\n",
    "        shape=[28,28,1], dtype=tf.float32, name=\"image\")\n",
    "\n",
    "    x = inputs\n",
    "    x = tf.keras.layers.GaussianNoise(stddev=gaussian_noise)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    for num_units in [64,32, 32]:\n",
    "        x = tf.keras.layers.Dense(num_units, activation='relu')(x)\n",
    "\n",
    "    pred = tf.keras.layers.Dense(hparams.num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return models.CustomModel(inputs=inputs, outputs=pred, \n",
    "                                    adv_training_with=adv_training_with)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy]\n",
    "optimizer = tf.keras.optimizers.RMSprop()\n",
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Model Without Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 53,706\n",
      "Trainable params: 53,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "fcc_model = get_fcc_model()\n",
    "fcc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4232 - accuracy: 0.8723 - val_loss: 0.1782 - val_accuracy: 0.9486\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2115 - accuracy: 0.9363 - val_loss: 0.1441 - val_accuracy: 0.9567\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1633 - accuracy: 0.9507 - val_loss: 0.1241 - val_accuracy: 0.9632\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1399 - accuracy: 0.9572 - val_loss: 0.1094 - val_accuracy: 0.9674\n",
      "\n",
      "\n",
      "313/313 - 0s - loss: 0.1145 - accuracy: 0.9655\n",
      "Test adversarial robustness for model trainedtrained without adversarial examles\n",
      "====================================================================================================\n",
      "FGSM - eps: 0.30 - accuracy: 0.03\n",
      "====================================================================================================\n",
      "Random Plus FGSM - eps: 0.30 - alpha: 0.3750 - accuracy: 0.03\n",
      "====================================================================================================\n",
      "Basic Iterative Method - eps: 0.30 - alpha: 0.0075 - num_iter: 40 - accuracy: 0.03\n",
      "====================================================================================================\n",
      "Iterative Least Likely (Iter 1.1) - eps: 0.30 - alpha: 0.0075 - num_iter: 40 - accuracy: 0.3\n",
      "====================================================================================================\n",
      "One Step Least Likely (Step 1.1) - eps: 0.30 - accuracy: 0.11\n"
     ]
    }
   ],
   "source": [
    "# Compile Model\n",
    "fcc_model.compile(optimizer=optimizer,\n",
    "              loss=loss, metrics=[\"accuracy\"])\n",
    "# Train Model\n",
    "fcc_model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=EPOCHS, validation_split=0.2)\n",
    "# Evaluate Model\n",
    "print(\"\\n\")\n",
    "evaluation = fcc_model.evaluate(x_test, y_test, verbose=2)\n",
    "# Test Adversarial Robustness\n",
    "fcc_model.test_adv_robustness(x_test[:100], y_test[:100], eps=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Without Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNo (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = get_cnn_model()\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1940 - accuracy: 0.9386 - val_loss: 0.0708 - val_accuracy: 0.9797\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 19s 12ms/step - loss: 0.0605 - accuracy: 0.9811 - val_loss: 0.0763 - val_accuracy: 0.9778\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 0.0472 - accuracy: 0.9856 - val_loss: 0.0393 - val_accuracy: 0.9886\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 19s 12ms/step - loss: 0.0400 - accuracy: 0.9875 - val_loss: 0.0376 - val_accuracy: 0.9897\n",
      "\n",
      "\n",
      "313/313 - 1s - loss: 0.0281 - accuracy: 0.9915\n",
      "\n",
      "\n",
      "Test adversarial robustness for model trainedtrained without adversarial examles\n",
      "====================================================================================================\n",
      "FGSM - eps: 0.30 - accuracy: 0.29\n",
      "====================================================================================================\n",
      "Random Plus FGSM - eps: 0.30 - alpha: 0.3750 - accuracy: 0.48\n",
      "====================================================================================================\n",
      "Basic Iterative Method - eps: 0.30 - alpha: 0.0075 - num_iter: 40 - accuracy: 0.12\n",
      "====================================================================================================\n",
      "Iterative Least Likely (Iter 1.1) - eps: 0.30 - alpha: 0.0075 - num_iter: 40 - accuracy: 0.71\n",
      "====================================================================================================\n",
      "One Step Least Likely (Step 1.1) - eps: 0.30 - accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "# Compile Model\n",
    "cnn_model.compile(optimizer=optimizer,\n",
    "              loss=loss, metrics=[\"accuracy\"])\n",
    "# Train Model \n",
    "cnn_model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=EPOCHS, validation_split=0.2)\n",
    "\n",
    "# Evaluate Model\n",
    "print(\"\\n\")\n",
    "evaluation = cnn_model.evaluate(x_test,y_test, verbose=2)\n",
    "# Test Adversarial Robustness\n",
    "print(\"\\n\")\n",
    "cnn_model.test_adv_robustness(x_test[:100], y_test[:100], eps=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training (With CNN Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training With FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 0.7061 - accuracy: 0.7602 - val_loss: 0.0932 - val_accuracy: 0.9693\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 34s 22ms/step - loss: 0.2713 - accuracy: 0.9114 - val_loss: 0.0632 - val_accuracy: 0.9808\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.2021 - accuracy: 0.9349 - val_loss: 0.0482 - val_accuracy: 0.9858\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 48s 32ms/step - loss: 0.1674 - accuracy: 0.9463 - val_loss: 0.0465 - val_accuracy: 0.9860\n",
      "\n",
      "\n",
      "313/313 - 1s - loss: 0.0396 - accuracy: 0.9869\n",
      "\n",
      "\n",
      "Test adversarial robustness for model trainedadversarially trained with FGSM - eps: 0.30\n",
      "====================================================================================================\n",
      "FGSM - eps: 0.30 - accuracy: 0.94\n",
      "====================================================================================================\n",
      "Random Plus FGSM - eps: 0.30 - alpha: 0.3750 - accuracy: 0.88\n",
      "====================================================================================================\n",
      "Basic Iterative Method - eps: 0.30 - alpha: 0.0075 - num_iter: 40 - accuracy: 0.37\n",
      "====================================================================================================\n",
      "Iterative Least Likely (Iter 1.1) - eps: 0.30 - alpha: 0.0075 - num_iter: 40 - accuracy: 0.99\n",
      "====================================================================================================\n",
      "One Step Least Likely (Step 1.1) - eps: 0.30 - accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Set Adversarial Training Parameters\n",
    "eps = 0.3\n",
    "attack_kwargs = {\"eps\": eps}\n",
    "adv_training_with = {\"attack\": attacks.Fgsm,\n",
    "                     \"attack kwargs\": attack_kwargs,\n",
    "                     \"num adv\": 16}\n",
    "\n",
    "cnn_model_fgsm = get_cnn_model(adv_training_with=adv_training_with)\n",
    "\n",
    "# Compile model\n",
    "cnn_model_fgsm.compile(optimizer=optimizer,\n",
    "                       loss=loss, metrics=[\"accuracy\"])\n",
    "cnn_model_fgsm.fit(x_train, y_train,\n",
    "                   batch_size=32,epochs=EPOCHS,\n",
    "                   validation_split=0.2)\n",
    "# Evaluate model\n",
    "print(\"\\n\")\n",
    "evaluation = cnn_model_fgsm.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "# Test adversarial robustness\n",
    "print(\"\\n\")\n",
    "cnn_model_fgsm.test_adv_robustness(x_test[:100], y_test[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training With Random+FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 50s 33ms/step - loss: 0.6349 - accuracy: 0.7876 - val_loss: 0.0864 - val_accuracy: 0.9746\n",
      "Epoch 2/4\n",
      "  95/1500 [>.............................] - ETA: 43s - loss: 0.3256 - accuracy: 0.8882"
     ]
    }
   ],
   "source": [
    "# Get adversarial training parameters\n",
    "eps = 0.3\n",
    "attack_kwargs = {\"eps\": eps, \"alpha\":1.25*eps}\n",
    "adv_training_with = {\"attack\": attacks.RandomPlusFgsm,\n",
    "                     \"attack kwargs\": attack_kwargs,\n",
    "                     \"num adv\": 16}\n",
    "# Build model\n",
    "cnn_model_random_plus_fgsm = get_cnn_model(adv_training_with=adv_training_with)\n",
    "\n",
    "# Compile model\n",
    "cnn_model_random_plus_fgsm.compile(optimizer=optimizer,\n",
    "                       loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "#Train model\n",
    "cnn_model_random_plus_fgsm.fit(x_train, y_train,\n",
    "                   batch_size=32,epochs=EPOCHS,\n",
    "                   validation_split=0.2)\n",
    "# Evaluate model\n",
    "print(\"\\n\")\n",
    "evaluation = cnn_model_fgsm.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "# Test adversarial robustness\n",
    "print(\"\\n\")\n",
    "cnn_model_random_plus_fgsm.test_adv_robustness(x_test[:100], y_test[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training With Basic Iterative Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set adversarial training parameters\n",
    "eps = 0.3\n",
    "num_iter = 40\n",
    "attack_kwargs = {\"eps\": eps, \"alpha\": eps/num_iter,\n",
    "                 \"num_iter\": num_iter}\n",
    "adv_training_with = {\"attack\": attacks.BasicIter,\n",
    "                     \"attack kwargs\": attack_kwargs,\n",
    "                     \"num adv\": 16}\n",
    "\n",
    "# Build model\n",
    "cnn_model_basic_iter = get_cnn_model(adv_training_with=adv_training_with)\n",
    "\n",
    "# Compile model\n",
    "cnn_model_basic_iter.compile(optimizer=optimizer,\n",
    "                       loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "cnn_model_basic_iter.fit(x_train, y_train,\n",
    "                   batch_size=32,epochs=EPOCHS,\n",
    "                   validation_split=0.2)\n",
    "# Evaluate model\n",
    "print(\"\\n\")\n",
    "evaluation = cnn_model_basic_iter.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "# Test adversarial robustness\n",
    "print(\"\\n\")\n",
    "cnn_model_basic_iter.test_adv_robustness(x_test, y_test, eps=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attack Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_demo(model, attack, images, labels):\n",
    "    \"\"\" Demo of adversarial attack on 20 images\n",
    "    model: tf,keras.Model\n",
    "    adv_attack: instance of AdversarialAttack\n",
    "    images: tensor of shape (20, height, width, channels)\n",
    "    labels: tensor of shape (20,)\n",
    "    \"\"\"\n",
    "    assert images.shape[0] == 20\n",
    "    fig, axs = plt.subplots(4, 11, figsize = (15,8))\n",
    "    \n",
    "    # Plot model predictions on clean images\n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            image = images[5*i+j]\n",
    "            label = labels[5*i+j]\n",
    "            ax = axs[i,j]\n",
    "            ax.imshow(tf.squeeze(image), cmap=\"gray\")\n",
    "            ax.axis(\"off\")\n",
    "            \n",
    "            prediction = model(tf.expand_dims(image, axis=0))\n",
    "            prediction = tf.math.argmax(prediction, axis=1)\n",
    "            prediction = tf.squeeze(prediction)           \n",
    "            color = \"green\" if prediction.numpy() == label.numpy() else \"red\"\n",
    "                    \n",
    "            ax.set_title(\"Pred: \" + str(prediction.numpy()),\n",
    "                         color=color, fontsize=18)\n",
    "    # Plot empty column \n",
    "    for i in range(4):\n",
    "        axs[i,5].axis(\"off\")\n",
    "        \n",
    "    # Plot model predictions on adversarial examples\n",
    "    if attack.name in [\"Iterative Least Likely (Iter 1.1)\", \n",
    "                       \"One Step Least Likely (Step 1.1)\"]:\n",
    "        attack_inputs = (images,)\n",
    "    else:\n",
    "        attack_inputs = (images, labels)\n",
    "\n",
    "    adv_examples = attack(*attack_inputs)\n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            image = adv_examples[5*i+j]\n",
    "            label = labels[5*i+j]\n",
    "            ax = axs[i,6+j]\n",
    "            ax.imshow(tf.squeeze(image),cmap=\"gray\")\n",
    "            ax.axis(\"off\")\n",
    "            \n",
    "            prediction = model(tf.expand_dims(image,axis=0))\n",
    "            prediction = tf.math.argmax(prediction, axis=1)\n",
    "            prediction = tf.squeeze(prediction)\n",
    "            color = \"green\" if prediction.numpy() ==label.numpy() else \"red\"\n",
    "            \n",
    "            ax.set_title(\"Pred: \" + str(prediction.numpy()),\n",
    "                         color=color, fontsize=18)\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    plt.figtext(0.16,0.93,\"Model Prediction on Clean Images\", fontsize=18)   \n",
    "    plt.figtext(0.55,0.93,\"Model Prediction on Adversarial Examples\", fontsize=18)\n",
    "    plt.figtext(0.1,1, adv_attack.specifics, fontsize=24, color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.2\n",
    "num_iter = 40\n",
    "adv_attack = attacks.IterativeLeastLikely(model=cnn_model, \n",
    "                                          eps=tf.constant(eps,dtype=tf.float32),\n",
    "                                          alpha=tf.constant(eps/num_iter,dtype=tf.float32),\n",
    "                                          num_iter=tf.constant(num_iter,dtype=tf.int32))\n",
    "\n",
    "image_demo(cnn_model, adv_attack, x_test[:20], y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.2\n",
    "num_iter = 40\n",
    "adv_attack = attacks.Fgsm(model=cnn_model,\n",
    "                          eps=tf.constant(eps,dtype=tf.float32))\n",
    "\n",
    "\n",
    "image_demo(cnn_model, adv_attack, x_test[:20], y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.2\n",
    "num_iter = 40\n",
    "adv_attack = attacks.BasicIter(model=cnn_model, \n",
    "                               eps=tf.constant(eps,dtype=tf.float32),\n",
    "                               alpha=tf.constant(eps/num_iter,dtype=tf.float32),\n",
    "                               num_iter=tf.constant(num_iter,dtype=tf.int32))\n",
    "\n",
    "image_demo(cnn_model, adv_attack, x_test[:20], y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.2\n",
    "num_iter = 40\n",
    "adv_attack = attacks.OneStepLeastLikely(model=cnn_model, \n",
    "                                        eps=tf.constant(eps,dtype=tf.float32))\n",
    "\n",
    "image_demo(cnn_model, adv_attack, x_test[:20], y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.2\n",
    "alpha = 1.25*eps\n",
    "num_iter = 40\n",
    "adv_attack = attacks.RandomPlusFgsm(model=cnn_model,\n",
    "                                    eps=tf.constant(eps,dtype=tf.float32),\n",
    "                                    alpha=tf.constant(alpha, dtype=tf.float32))\n",
    "\n",
    "\n",
    "image_demo(cnn_model, adv_attack, x_test[:20], y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversarial_training",
   "language": "python",
   "name": "adversarial_training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
